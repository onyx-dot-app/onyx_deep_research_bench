Query ID: 71
============================================================

QUESTION:
Acting as an expert in K-12 education research and an experienced frontline teacher, research and analyze global case studies on the practical application of AIGC (AI-Generated Content) in primary and secondary school classrooms. Identify, categorize, and analyze various application approaches and their corresponding examples. The final report should present an overall framework, detailed category discussions, practical implementation methods, future trends, and recommendations for educators.

============================================================

RESEARCH TASKS (6 total):
  #1: Research (2023–Feb 2026) global K–12 classroom case studies of AIGC (generative AI) use in primary/secondary classrooms. Find concrete examples by country/region, grade band, subject, and context; capture tools/models used (e.g., ChatGPT, Gemini, Claude, Copilot, image/audio generators), lesson design, teacher role, student tasks, reported outcomes and constraints, and citations/links.
  #2: Research frameworks or typologies (2023–Feb 2026) for categorizing practical generative AI/AIGC applications in K–12 classrooms. Identify category definitions and classification criteria (teacher-facing planning/assessment, student learning, co-creation, differentiation, accessibility, language learning, project-based learning, etc.) and look for research syntheses, UNESCO/OECD, ISTE/ASCD, academic papers, and practitioner guides with evidence.
  #3: Research governance/ethics/policy conditions shaping classroom AIGC use globally (2023–Feb 2026): privacy/data protection, age limits, consent, IP/copyright, bias/accessibility, assessment validity, safeguarding. Identify leading jurisdiction/system operational approaches (e.g., EU AI Act + GDPR, US state/district policies, UK DfE, Australia, Singapore, Canada, China) including approved tool lists, walled gardens, training, monitoring, incident response.
  #4: Research practical implementation methods/design patterns for safe and effective AIGC (generative AI) use in K–12 classrooms (primary vs secondary), 2023–Feb 2026. Look for lesson templates, prompt scaffolds, verification routines, citation/provenance practices, AI literacy mini-lessons, classroom management routines, offline/low-tech adaptations, and common failure modes and mitigations, drawing from research papers, district guides, and case studies.
  #5: Research future trends (2026–2028) for AIGC/generative AI in K–12 and education systems as predicted in 2023–Feb 2026 sources (UNESCO, OECD, WEF, edtech research, standards bodies). Identify likely developments: multimodal tutors, agentic workflows, on-device models, curriculum-embedded AI, assessment redesign, provenance/citation standards, regulation impacts, and what educator recommendations/roadmaps are suggested.
  #6: Find additional (2023–Feb 2026) concrete K–12 classroom case studies of AIGC use beyond those already identified (Uruguay personalization; Germany history role-play; Australia disability science; Singapore SLS tools; New Zealand assessment authenticity; Canada TDSB AIAS). Prioritize underrepresented regions (Africa, Middle East, South Asia), plus US/UK/Europe primary/secondary examples in subjects like ELA writing, languages, arts, computing, and multimodal content generation; capture tools, lesson workflow, outcomes, constraints with citations.

============================================================

ANSWER:
### 1) What counts as a “classroom AIGC case study,” and the **minimum evidence set** to document one

Because “AIGC in classrooms” spans everything from a teacher using ChatGPT to draft a worksheet to a ministry deploying AI inside a national LMS, it helps to standardize documentation. Across the empirical and practice-facing literature, the **minimum evidence set** that makes a case study genuinely useful (replicable, auditable, comparable) is:

**A. Context**
- Country/region; school type (public/private; urban/rural); governance constraints (approved tools, blocked tools, age rules).
- Grade band (primary / lower secondary / upper secondary), subject/unit, class size, device/internet access model.

**B. Tooling (AIGC specifics)**
- Which model/tool (e.g., ChatGPT-3.5 vs GPT‑4; Copilot; Midjourney; a district platform wrapping an LLM).
- Account model (student accounts vs teacher-only; walled garden vs public web).
- Data handling assumptions (is input retained for training? are PII rules enforced?).

**C. Pedagogical design**
- Learning objective(s) and what students must still learn *without* AI (“teach the long way first” principle) [[30]](https://www.sreb.org/sites/main/files/file-attachments/2025_ai_in_k-12classroom_guidance.pdf).
- The AIGC role: tutor / feedback coach / co-writer / scenario simulator / differentiation engine / assessment assistant.
- The **Human→AI→Human loop**: what’s human-authored before AIGC, what AIGC generates, and what humans verify/edit at the end [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf).

**D. Classroom workflow**
- Teacher moves (mini-lesson, modeling, constraints, checkpoints).
- Student tasks and artifacts (prompt logs, drafts, revisions, citations/disclosure statements, reflections, performance evidence).
- Time-on-task and where AIGC is used (in class vs homework vs after-school).

**E. Outcomes + constraints**
- What changed (learning gains, engagement, equity signals, teacher workload, academic integrity incidents).
- Failure modes observed (hallucinations, bias, overreliance, access inequities, privacy risks) and mitigations used.

Many published reports *do not* provide enough workflow detail for replication (systematic review evidence) [[27]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1647573/full). So, in the case syntheses below, I explicitly distinguish **(i) peer‑reviewed classroom interventions**, **(ii) system deployments with practitioner testimony**, and **(iii) pilots/prototypes/press reports**—all valuable, but not equally strong evidence.

---

## 2) An overall framework to categorize practical AIGC classroom applications (clear criteria, minimal overlap)

A workable global classification needs to (a) describe what teachers actually do, (b) separate “who benefits,” and (c) handle different levels of AI involvement.

### 2.1 Three-layer classification (use together)

#### Layer 1 — **Primary beneficiary (“facing”)**
Borrowing the widely used distinction between student-facing, teacher-facing, and system-facing AI [[23]](https://www.internetsegura.pt/sites/default/files/2022-11/ethical-guidelines-on-the-use-of-artificial-intelligence-nc0722649enn.pdf):

1) **Student-facing**: AIGC directly mediates student learning activities (tutoring, feedback, co-creation, simulation).
2) **Teacher-facing**: AIGC supports teaching work (planning, differentiation design, resource creation, feedback drafting).
3) **System-facing**: AIGC embedded in platforms/processes at scale (national LMS assistants, district-approved tools, analytics and governance).

**Classification rule:** Choose the category based on *who interacts with AIGC as part of the learning loop* most directly and whose work is being augmented.

#### Layer 2 — **Pedagogical function (what AIGC is doing)**
Synthesizing OECD’s teaching dimensions (feedback/support; dialogue; rich content; engagement) [[16]](https://one.oecd.org/document/EDU/EDPC(2023)11/en/pdf) and K–12 activity patterns found in a broad empirical mapping review (dialogic tutoring/formative feedback; iterative co‑creation; project-based problem solving; simulation/game; assessment support) [[28]](https://www.mdpi.com/2079-8954/13/10/840):

A) **Tutoring / dialogic explanation** (Q&A, guided practice, step-by-step hints)  
B) **Feedback and revision coaching** (formative feedback on drafts, metacognitive revision planning)  
C) **Differentiation / personalization** (leveling texts, generating tailored practice, accessibility supports)  
D) **Co-creation / production** (writing, multimedia generation, coding, creative artifacts)  
E) **Simulation / role-play / scenario** (historical figure interviews, debate partners, lab scenarios)  
F) **Assessment & academic integrity design** (authenticity checks, AI-aware rubrics, process evidence)  
G) **AI literacy / critical evaluation** (bias, hallucinations, source checking, disclosure norms)

**Classification rule:** Pick the **dominant learning mechanism** (e.g., “role-play” even if feedback occurs).

#### Layer 3 — **Level of AI involvement (scaffolded permission)**
For classroom practicality, educators need a “how much AI is allowed” scale. Washington OSPI’s scaffolding levels provide a clear progression from no AI to co-creator, with transparency expectations increasing with involvement [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf).

- Level 1 No AI  
- Level 2 Brainstorming help  
- Level 3 Drafting help  
- Level 4 Collaborative creation (AI content may be included, but critically edited)  
- Level 5 Co-creator (extensive use + rationale + integrity safeguards) [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf)

**Classification rule:** Set the allowed level **per task phase** (ideation vs drafting vs final submission), not as a blanket rule for the entire unit.

---

## 3) Global case studies (2023–Feb 2026) organized by application approach

Below are the most practice-relevant global cases captured in the research record, grouped by the framework above. For each category, I include: *how it worked*, *examples*, *impacts*, and *constraints*.

---

# Category A — Student-facing **tutoring / dialogic explanation**

### A1) **Nigeria (Edo State)** — after-school English with Microsoft Copilot (ChatGPT-powered), large-scale pilot with measured gains
- **Setting:** Edo State, Nigeria; 6-week after-school program (June–July 2024) for **800 first‑year senior secondary students** in computer labs, twice weekly [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).  
- **Tool:** Microsoft Copilot (powered by ChatGPT) [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).  
- **Workflow (highly concrete):**
  1) Teacher introduces weekly topic.
  2) Students interact with Copilot on grammar + writing tasks.
  3) Teachers act as “orchestra conductors,” starting with suggested prompts, mentoring during interaction, adding prompts, and closing with reflection exercises [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).  
- **Outcomes (reported by World Bank):**
  - Students randomly assigned to the program outperformed controls on a pen-and-paper test covering English, AI knowledge, and digital skills [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).
  - Reported spillover to end-of-year exams beyond the intervention topics [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).
  - Benefits extended across achievement levels; girls appeared to gain more, narrowing gaps [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).
  - Reported effect size ~0.3 SD; “dose-response” (more attendance → larger gains) [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).  
- **Constraints observed:**
  - Many students lacked basic computer skills; early weeks consumed by setup and basic digital skills [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).
  - Power/internet outages disrupted sessions; need backup connectivity/power [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).
  - Teacher-identified risks: overreliance, hallucinations, misuse—mitigations needed [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).  
**Why it matters:** This is one of the strongest “tutoring” cases in underrepresented regions, combining teacher-facilitated workflow + outcome measurement at scale [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria), [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).

### A2) **United Arab Emirates** — high school physics with ChatGPT (quasi-experimental gains)
- **Setting:** UAE high school physics; focus on Newton’s second law; two-group quasi-experimental design [[79]](https://www.ejmste.com/article/making-a-revolution-in-physics-learning-in-high-schools-with-chatgpt-a-case-study-in-uae-14983).  
- **Tool:** ChatGPT [[79]](https://www.ejmste.com/article/making-a-revolution-in-physics-learning-in-high-schools-with-chatgpt-a-case-study-in-uae-14983).  
- **Outcomes:** Improved academic performance on pre/post tests for both genders; slightly greater improvement for female students; high engagement reported [[79]](https://www.ejmste.com/article/making-a-revolution-in-physics-learning-in-high-schools-with-chatgpt-a-case-study-in-uae-14983).  
- **Limitations:** The accessible summary does not provide enough detail on lesson routine, prompts, or classroom management, so replication detail is limited [[79]](https://www.ejmste.com/article/making-a-revolution-in-physics-learning-in-high-schools-with-chatgpt-a-case-study-in-uae-14983).

### A3) **Italy** — GPT‑4 interactive homework tutor for EFL (RCT, homework component)
- **Setting:** Italian technical institute; English as a second language; four classes with the same teacher; treatment replaced traditional homework with GPT‑4 interactive sessions; control had typical homework [[83]](https://arxiv.org/pdf/2409.15981).  
- **Tool:** GPT‑4 [[83]](https://arxiv.org/pdf/2409.15981).  
- **Workflow:** Teacher provided for each homework exercise: purpose (objectives), task description, and an example; GPT‑4 was prompted to run an interactive session aligned to these elements [[83]](https://arxiv.org/pdf/2409.15981).  
- **Outcomes:** Improved learning outcomes (notably grammar), higher engagement and satisfaction; students wanted to continue using it [[83]](https://arxiv.org/pdf/2409.15981).  
- **Constraints:** Not fully controllable because students in both groups could still use ChatGPT independently; broader GenAI risks acknowledged (plagiarism, hallucinations, jailbreaks) [[83]](https://arxiv.org/pdf/2409.15981).  
**Why it matters:** A rare RCT-style design focusing on *interactive* practice rather than one-shot answer generation.

---

# Category B — Student-facing **feedback and revision coaching**

### B1) **Singapore** — platform-integrated “Feedback Assistants” (open-response marking + immediate feedback)
- **Setting:** Singapore MOE tools integrated in the national Student Learning Space (SLS) [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them), [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
- **Tools/functions:** Short Answer Feedback Assistant, Annotated Feedback Assistant, Math Feedback Assistant, plus an Adaptive Learning System and other assistants [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them), [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
- **Classroom example (secondary science):** A biology subject head uses the short-answer feedback assistant to build SLS quizzes; student responses are matched to her mark scheme and immediate feedback is given; she refines feedback as needed [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
- **Reported impacts (practitioner testimony):**
  - Students receive immediate feedback; motivation/confidence can improve [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).
  - Teachers shifted from multiple choice to more content-based questions because marking became more feasible, enabling more higher-order assessment [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
- **Constraints:** Teachers still manually review and correct AI feedback; marking inaccuracies occur; time savings not always fully realized [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
**Why it matters:** Illustrates a **walled-garden** model with teacher-editable feedback, which is closer to how systems may deploy AIGC responsibly at scale [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).

### B2) **Canada (Toronto District School Board)** — AI-supported feedback loops + metacognitive revision strategies (practice-based inquiry)
- **Setting:** Multi-class teacher inquiry (mostly grades 9–12, but also some early primary through K–8); subjects include English, History, Social Sciences, Math, Science, French, and full elementary coverage [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
- **Tools referenced:** Copilot, ChatGPT, Gemini, Diffit [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
- **Concrete classroom patterns:**
  - Middle school geography: Copilot gives immediate feedback; students must reflect on feedback before revising [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).
  - Grade 9 English/History: students compile teacher feedback and use Gemini to generate personalized revision strategies (explicitly teaching “how to learn,” not outsourcing writing) [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).
  - Grade 12 Economics: students use AI as drafting/feedback partner for current events presentations; rubric includes “ownership of the presentation” to separate student thinking from AI assistance [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
- **Outcomes (reported by educators):** shifts toward clearer assessment purpose, more iterative feedback cycles, improved student self-regulation and engagement with feedback; implementation constrained by evolving district policy clarity [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
**Why it matters:** Shows assessment redesign and feedback literacy as the *real* leverage point, not “AI grading.”

### B3) **UK (England) proof-of-concept** — AI-assisted marking/feedback workflow for primary writing (prototype, not deployment)
- **Setting:** User research + prototype testing (8 primary teachers evaluated outputs); not ready for school deployment [[86]](https://dera.ioe.ac.uk/id/eprint/40811/1/Use_cases_for_generative_AI_in_education_user_research_report.pdf).  
- **Workflow features:** paste task + student essay → error highlights linked to national curriculum; teacher feedback summary; student-friendly feedback; autogenerated practice worksheets by error type [[86]](https://dera.ioe.ac.uk/id/eprint/40811/1/Use_cases_for_generative_AI_in_education_user_research_report.pdf).  
- **Why it matters:** Demonstrates a plausible near-future workflow for formative feedback, while also showing that output quality/safety/integration concerns kept it from being “ready” [[86]](https://dera.ioe.ac.uk/id/eprint/40811/1/Use_cases_for_generative_AI_in_education_user_research_report.pdf).

---

# Category C — Student-facing **differentiation/personalization** (dynamic content generation)

### C1) **Uruguay (primary, grades 4–6)** — real-time personalized materials with ChatGPT + Midjourney
- **Setting:** Two schools; **110 students aged 8–14** in grades 4–6 [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full), [[5]](https://www.mdpi.com/2071-1050/15/18/14025).  
- **Tools:** ChatGPT‑3.5 and ChatGPT‑4; Midjourney for illustrations [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full).  
- **Workflow:** Instructional content followed curriculum goals; text, illustrations, and exercises generated and dynamically adjusted to pupil needs during lessons [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full).  
- **Outcomes:** Reported improved motivation and performance; materials tailored to varying knowledge levels; real-time adjustments improved “cognitive ergonomics” [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full). Pupils largely enjoyed AI-modified materials [[5]](https://www.mdpi.com/2071-1050/15/18/14025).  
- **Constraints:** Authors note the broader evidence base for school implementations was sparse, and tools need refinement/optimization for inclusive, sustainable benefits [[5]](https://www.mdpi.com/2071-1050/15/18/14025).  
**Why it matters:** One of the clearest documented classroom implementations of *dynamic personalization* rather than generic chatbot Q&A.

### C2) **Singapore Adaptive Learning System (ALS)** — pathwaying by competence (upper primary math; upper secondary geography)
- **Setting:** ALS available for **Primary 5 to Secondary 2 Math** and upper secondary geography; provides personalized paths based on responses [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education); teacher example described in upper primary math revision [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
- **Workflow example:** Teacher uses ALS for revision; students are profiled into pathways; teacher gets real-time progress data and targets support while others move forward [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
- **Constraint:** This is system deployment with practitioner report, not a controlled evaluation [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).

### C3) **Kenya (teacher-enabled differentiation)** — chatbot-assisted simplification and quiz generation (teacher-facing but student impact via adapted instruction)
- **Setting:** Kenyan primary teacher planning shortly before class; nonprofit Kalasik chatbot using an OpenAI model; teacher cross-checks with textbook; generates quizzes; asks for “simpler way to teach” challenging content [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).  
- **Constraints:** Internet access limitations; affordability of data bundles; tool sometimes “spills” beyond intended Kenyan curriculum sources [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).  
**Why it matters:** Shows a low-resource “just-in-time differentiation” use pattern (teacher adapts instruction quickly) under connectivity constraints.

---

# Category D — Student-facing **co-creation / production** (writing, multimodal, coding)

### D1) **Malaysia (Year 6 ESL writing)** — ChatGPT as writing enhancer (qualitative perceptions)
- **Setting:** Year 6 pupils in a Malaysian primary school (10 pupils); interviews on experiences using ChatGPT to enhance writing [[81]](https://kwpublications.com/papers_submitted/17507/chatgpt-for-esl-writing-a-case-study-on-year-6-esl-pupils-perceptions.pdf).  
- **Reported benefits:** improved grammar/vocabulary and engagement; increased confidence/creativity/motivation [[81]](https://kwpublications.com/papers_submitted/17507/chatgpt-for-esl-writing-a-case-study-on-year-6-esl-pupils-perceptions.pdf).  
- **Risks noted by pupils:** dependency/overreliance; access as implementation barrier [[81]](https://kwpublications.com/papers_submitted/17507/chatgpt-for-esl-writing-a-case-study-on-year-6-esl-pupils-perceptions.pdf).  
- **Limitations:** Perception-based qualitative study; limited workflow detail [[81]](https://kwpublications.com/papers_submitted/17507/chatgpt-for-esl-writing-a-case-study-on-year-6-esl-pupils-perceptions.pdf).

### D2) **US (Utah, Jordan School District)** — SchoolAI platform: writing coaching and constrained chat experiences (pilot → district-wide rollout)
- **Setting:** Summer pilot with ~100 teachers expanding; later partnership announcement for district-wide integration (67 schools; 3,350 educators; 57,800 students) [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try), [[85]](https://www.utahbusiness.com/press-releases/2024/02/08/schoolai-jordan-school-district-ai-partnership/).  
- **Workflow examples (reported):**
  - Teacher-configured chat “clone of me” for topic conversations within parameters; bot asks questions and adapts to student responses [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try).
  - Writing companion offers instant feedback; teachers use it to manage feedback load across large student counts [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try).
  - Creative engagement: e.g., reviewing mitosis in SpongeBob voice (illustrative) [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try).  
- **Guardrails claims:** tool designed so students can’t trick it into writing the whole essay (vendor claim) [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try).  
- **Evidence caveat:** media report + press release; not independent evaluation [[84]](https://www.westjordanjournal.com/2023/09/11/465161/jordan-district-teachers-give-ai-a-try), [[85]](https://www.utahbusiness.com/press-releases/2024/02/08/schoolai-jordan-school-district-ai-partnership/).  
**Why it matters:** Illustrates the emerging product pattern: **teacher-controlled “safe chat rooms”** (bounded prompts + moderation dashboards), likely to expand globally.

---

# Category E — Student-facing **simulation / role-play / scenario learning**

### E1) **Germany (Year 9 history)** — “interview a historical figure” via ChatGPT on a privacy-compliant platform
- **Setting:** German secondary history; Year 9; n=21; task: interview a chatbot role-playing a historical figure [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).  
- **Tool/access model:** “schulKI” platform providing access to ChatGPT in compliance with German data protection expectations [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).  
- **Analysis focus:** types of student prompts and AI responses (grounded theory; sociocultural history education lens) [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).  
- **Risks highlighted:** bias, false information, outdated knowledge cutoffs, lack of citations; threats to history education and democratic discourse if uncritical use spreads [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).  
**Why it matters:** Role-play is highly engaging, but history is also where hallucinations/bias can be most damaging—this case shows both the promise and the epistemic danger.

### E2) **Singapore “Learning Assistant (LEA)”** — guided questioning and role-taking
- **Function:** LEA “asks guiding questions” and can “take on different roles to encourage different ways of thinking” [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
- **Note:** This is a system tool description; classroom-level outcomes depend on implementation.

---

# Category F — Assessment & academic integrity design (AI-aware assessment, authenticity evidence)

This category is *not* “using AI to grade,” which some governance guidance discourages as a priority risk area [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html). It is about **designing assessment in an AI-saturated world**.

### F1) **New Zealand secondary schools (Aotea College)** — whole-school response: checkpoints, supervision, verbal questioning
- **Trigger:** 2023 trend of students using GenAI for “researching” and paraphrasing into plagiarism [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf).  
- **School response:** AI working group; updated assessment policy; staff handbook; PLD; community info; consistency across subjects [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf).  
- **Classroom techniques:** extra checkpoints; supervised components; device checks; knowing student voice; verbal questioning to confirm understanding [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf).  
- **Why it matters:** A practical school operations model for moving from “panic + detection” to “policy + pedagogy + consistent routines.”

### F2) **New Zealand secondary schools (Hobsonville Point)** — “students must prove they did not use GenAI” + version history + restorative conversations
- **Trigger:** increase in plagiarism cases linked to GenAI in 2023 internal assessments [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).  
- **Key design choice:** did **not** revert to pen-and-paper (equity/inclusion reasons); instead built authenticity processes [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).  
- **Core workflow requirements:**
  - Checkpoints embedded in all internal assessments (early detection and support) [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
  - Standard assessment templates with checkpoint evidence requirements [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
  - Submission of original working documents with full version history (detect content dumping; group contribution) [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
  - Voice/vocabulary checks + verbal questioning [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
  - Restorative conversations with students/families to address underlying causes; staff supported by leadership [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).  
- **Outcome:** “significant reduction” in inappropriate AI use; improved staff confidence; families valued checkpoints for organization [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).  
**Why it matters:** This is among the clearest operational assessment frameworks that is both *authenticity-focused* and *student-supportive*.

### F3) **Canada (TDSB inquiry)** — explicit AI-aware rubrics and “ownership” criteria
- **Approach:** Using an “AI Assessment Scale (AIAS)” to redesign assessments so AI use is *accounted for*, not ignored [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
- **Examples:** rubrics that grade “ownership” and require in-person performance components (e.g., students design warm-ups using AI but must lead and explain routines live) [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
**Why it matters:** Moves beyond policing to **designing assessment evidence that AI can’t fully fake** (performance, reflection, reasoning, process artifacts).

---

# Category G — Inclusion, accessibility, and special educational needs (SEND)

### G1) **Australia secondary science (students with disability)** — ChatGPT as “cognitive prosthesis,” but with metacognitive constraints
- **Setting:** Inclusive secondary science classroom; multiple-case study of three students with disability using ChatGPT agentically [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).  
- **Data sources:** interviews, chat logs, teacher worksheets, lesson video [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).  
- **Findings:** students made meaningful choices to use ChatGPT, but faced metacognitive challenges and cognitive constraints; misalignment between choices and capability [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).  
- **Recommendations:** customize GenAI for specific learning needs; align with Universal Design for Learning; clarify teacher vs education assistant roles [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).  
**Why it matters:** A grounded caution: “access” is not automatically “agency.” Students may need explicit scaffolds to use AIGC productively.

### G2) **Singapore speech evaluation tool**
- **Function:** automated feedback on pronunciation/reading fluency/speech clarity (English and Mother Tongue languages) [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
- **Why it matters:** AIGC-adjacent (AI-generated feedback rather than content), but practically important for accessibility and language learning at scale.

---

# Category H — Teacher-facing planning, resource creation, and workload reduction (often the first safe entry point)

Many policy bodies observe “more immediate benefits and fewer risks” from teacher-facing uses than pupil-facing uses [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education). Teacher usage patterns also show strong emphasis on lesson planning and activity generation (OECD TALIS) [[64]](https://www.oecd.org/en/publications/results-from-talis-2024_90df6235-en/full-report/teaching-for-today-s-world_eefb146b.html).

### H1) **Kenya** — just-in-time lesson planning and quiz generation under teacher shortages
- **Workflow:** teacher generates lesson plan ~30 minutes before class; cross-checks with textbooks; generates quizzes; asks for simpler teaching methods [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).  
- **Impact (self-report):** reduced planning burden; more time for students [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).  
- **Constraints:** connectivity, data affordability; equity concerns if some students have home access [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).

### H2) **Singapore “Authoring Copilot”** — lesson planning inside SLS
- **Function:** generates lesson sections/activities/quizzes from teacher inputs (objectives, keywords, prior knowledge) [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them), [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
- **Constraint:** at least in one teacher report, tool couldn’t read Chinese at the time; required translation to English [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).  
- **Why it matters:** Illustrates the system direction: teacher-facing AIGC embedded in a controlled platform, aligned to national content pipelines [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).

### H3) **Uruguay personalization lesson creation** — teacher uses ChatGPT + Midjourney to design differentiated materials
- **Teacher work:** curated lesson materials created with ChatGPT-3.5/4 and Midjourney [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full).  
- **Impact:** enabled rapid creation of leveled resources for diverse learners [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full), [[5]](https://www.mdpi.com/2071-1050/15/18/14025).  
- **Constraint:** requires strong teacher review for accuracy and appropriateness [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full), [[5]](https://www.mdpi.com/2071-1050/15/18/14025).

---

## 4) Cross-case synthesis: what application approaches are emerging globally?

Across the cases, the “practical application approaches” fall into a small set of repeatable patterns:

1) **Teacher-orchestrated tutoring** (Nigeria after-school Copilot; Italy GPT‑4 homework) where AIGC is an interactive coach, but teachers frame tasks and reflection [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria), [[83]](https://arxiv.org/pdf/2409.15981).  
2) **Platform-embedded feedback assistants** (Singapore SLS) where teachers can edit rubrics/feedback and outputs are constrained by the platform [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them), [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
3) **Dynamic personalization of materials** (Uruguay) where AIGC generates leveled text/images/exercises in real time [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full), [[5]](https://www.mdpi.com/2071-1050/15/18/14025).  
4) **Role-play and historical/socio-scientific simulation** (Germany history interview) with high engagement but high epistemic risk if not audited [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).  
5) **Assessment redesign and authenticity workflows** (NZ checkpoints/version history + Canada AIAS-style rubrics) shifting from “detection” to “designing evidence” [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf), [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf), [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).  
6) **Inclusion-oriented mediated use** (Australia disability case) emphasizing UDL alignment and metacognitive scaffolds [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).  
7) **Teacher workload relief via lesson planning and quiz generation** (Kenya; Singapore authoring tools) as a low-risk entry point when privacy is protected and outputs are reviewed [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/), [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).

---

## 5) Practical implementation methods (teacher-ready design patterns)

This section translates the research and cases into **classroom-operational routines**.

### 5.1 The core routine: **Human → AI → Human** (non-negotiable)
Washington OSPI frames safe use as starting with human inquiry and ending with human reflection and empowerment [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf). In practice:

- **Human (before):** set purpose, success criteria, audience, constraints; teach the concept first when necessary [[30]](https://www.sreb.org/sites/main/files/file-attachments/2025_ai_in_k-12classroom_guidance.pdf).  
- **AI (during):** generate ideas/drafts/questions/variants; simulate dialogue; produce leveled materials.  
- **Human (after):** verify, edit, cite/disclose, reflect, and demonstrate understanding (performance or oral defense).

### 5.2 Prompt scaffolds that work in real classrooms
Even when sources don’t give full prompt libraries, the recurring strategy is: **constrain + contextualize + require reasoning**.

**A reliable scaffold for students (especially grades 6–12):**
1) Role: “You are a tutor/coach, not the answerer.”
2) Task: restate the assignment in your own words.
3) Constraints: grade level, length, vocabulary, include examples, ask me questions first.
4) Verification: “Flag anything you’re unsure about; suggest how to verify.”

**For teachers generating materials:**
- Ask for *multiple versions* (below/at/above grade level) and *include misconceptions* to address.
- Request alignment to curriculum outcomes—but still cross-check (Kenya teacher cross-checks with textbook) [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).

### 5.3 Verification and “AI auditing” as a taught skill (not a reminder)
Hallucinations and fabricated sources are a known risk [[47]](https://www.oregon.gov/ode/educator-resources/teachingcontent/Documents/Generative%20Artificial%20Intelligence%20(AI)%20in%20K-12%20Classrooms%20v2.pdf). Build **verification** into task requirements:

- **Lateral reading / cross-source checking** for factual claims (especially history/science) [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml), [[47]](https://www.oregon.gov/ode/educator-resources/teachingcontent/Documents/Generative%20Artificial%20Intelligence%20(AI)%20in%20K-12%20Classrooms%20v2.pdf).  
- Require students to annotate: “What I accepted / what I rejected / what I verified and how.”
- Use a “two-source rule”: any factual claim used in final work must be confirmed by two non-AI sources (or one authoritative source).

### 5.4 Transparency: citation/disclosure norms
Policy and guidance increasingly expect disclosure of AI assistance (e.g., EU-aligned school guidance requires “AI-assisted” disclaimers and transparency) [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf). Classroom practice:

- Require an **AI use statement**:
  - Tool name, date/version (if known), what it was used for (brainstorming, drafting, feedback), and what the student changed.
- For older students: include a short **prompt log** (or summarized prompt history).

### 5.5 Assessment redesign: make AI misuse less rewarding
The New Zealand cases show that authenticity improves when teachers:
- Build **checkpoints** with required evidence, not just a final submission [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf), [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
- Collect **version histories** to detect content dumping and observe thinking over time [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
- Use **verbal questioning** / oral defense to confirm understanding [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf), [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).  
Canada’s inquiry adds:
- Rubric criteria like “ownership” and requiring **in-person performance evidence** (presentations, demonstrations) [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).

**Teacher-ready assessment pattern (works across subjects):**
- Phase 1 (in class): planning + hypothesis + outline (can allow Level 2 AI brainstorming [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf)).
- Phase 2 (drafting): iterative drafts with teacher checkpoint; if AI drafting allowed, require marked edits and reasoning.
- Phase 3 (verification): citations + fact-check log.
- Phase 4 (defense): short oral explanation, conferencing, or performance task.

### 5.6 Primary vs secondary: developmentally appropriate implementation
- **Primary:** emphasize AI literacy *without* heavy reliance on open chatbots; focus on teacher-facing generation and curated, walled-garden tools where possible; teach “AI is not a person” and basic verification habits (Digital Promise explicitly notes AI literacy can be taught without using AI tools, particularly in early grades) [[54]](https://files.eric.ed.gov/fulltext/ED671235.pdf).  
- **Secondary:** expand to structured student-facing use with explicit scaffolding levels and clear integrity expectations [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf).

### 5.7 Inclusion/SEND: scaffold agency, don’t assume it
The Australian disability science case shows students may choose to use ChatGPT but struggle with metacognition and capability alignment [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048). Practical moves:
- Provide **goal prompts** (“Ask it to quiz you”; “Ask for two hints, not the answer”).
- Use **UDL-aligned templates** and teacher/EA co-monitoring [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).
- Teach “stop rules”: when to disengage and ask a human.

### 5.8 Infrastructure and access planning (real-world constraints)
Nigeria’s Edo pilot shows that learning benefits can be large, but time is lost to account setup and basic computer skills; outages disrupt learning [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria). Plan:
- A “Day 0” onboarding session (accounts, norms, safe use).
- Offline fallback tasks for outage days.
- Equity plan for students without home access (also raised as an equity concern in Kenya) [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).

---

## 6) Governance, ethics, and policy conditions shaping classroom AIGC globally (what educators must account for)

### 6.1 Global principles converging across jurisdictions
UNESCO emphasizes that regulation lags deployment, privacy may be unprotected, and institutions must validate GenAI for ethical and pedagogical appropriateness [[1]](https://unesdoc.unesco.org/ark:/48223/pf0000386693). OECD’s governance analysis shows most jurisdictions rely on non-binding guidance, prioritizing privacy/data protection, reliability, transparency, bias, and cultural/linguistic relevance [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html).

### 6.2 Three dominant operational models worldwide

#### Model 1 — **Walled garden / platform-integrated AI**
- Singapore MOE exemplifies this: AI tools embedded in SLS with guardrails and an AIEd ethics framework (Agency, Inclusivity, Fairness, Safety) [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).  
**Pros:** easier privacy control, age-appropriate design, consistent access.  
**Cons:** feature gaps, language limitations (e.g., teacher report of Chinese limitation) [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).

#### Model 2 — **Approved-tool + consent + privacy-first controls**
- Victoria (Australia) requires opt-in parental consent when tools require personal info beyond school email/password, bans uploading PII and generating depictions of students, and restricts staff using GenAI to communicate with parents/students or to write reports/judge achievement [[37]](https://www2.education.vic.gov.au/pal/generative-artificial-intelligence/policy).  
**Pros:** strong child safety/privacy stance.  
**Cons:** can slow innovation; requires clear approved tool processes.

#### Model 3 — **Local autonomy with guidance (teacher-facing first)**
- UK DfE explicitly states more immediate benefits and fewer risks from teacher-facing use; pupil-facing use requires safeguards, supervision, filtering/monitoring, and legal compliance (data protection, safeguarding, IP) [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education).  
**Pros:** pragmatic transition model.  
**Cons:** uneven implementation; potential inequity across schools.

### 6.3 EU legal context: GDPR + AI Act pressure (and what schools do with it)
European Schools guidance (effective May 2025) explicitly requires compliance with GDPR and the EU AI Act; forbids inputting personal/non-public data into GenAI tools; requires output review and disclosure; and restricts pupil use unless tools are approved with regulations in place [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf). This is a concrete example of how EU constraints shape classroom implementation.

The official EU AI Act timeline indicates key obligations phase in, with major enforcement beginning **02 Aug 2026** (including transparency rules and high-risk system rules) [[73]](https://ai-act-service-desk.ec.europa.eu/en/ai-act/timeline/timeline-implementation-eu-ai-act). Even outside Europe, vendors serving EU contexts will likely propagate these compliance features globally.

### 6.4 Privacy, IP, age limits, and safeguarding: classroom-level implications
- **Privacy:** do not input PII into public tools; many policies explicitly warn that prompts may be stored/used for training [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf), [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education).  
- **Age restrictions:** many tools set minimum ages; OECD notes guidance often aligns to tool ToS (e.g., under 13 prohibited; under 18 parental approval) [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html).  
- **IP/copyright:** UK DfE warns against allowing students’ original work to train models without permission and highlights secondary infringement risks [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education).  
- **Safeguarding:** DfE stresses risk assessment and warns about misuse such as generating realistic scam communications [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education).  
- **Bias and cultural relevance:** OECD notes cultural/linguistic relevance is a national concern (notably for non-English settings) [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html); UNESCO stresses protecting linguistic/cultural diversity [[1]](https://unesdoc.unesco.org/ark:/48223/pf0000386693).

---

## 7) Future trends (2026–2028) that are most likely, based on 2023–Feb 2026 evidence

### Trend 1 — **Teacher-facing AIGC becomes universal; student-facing grows via controlled platforms**
OECD TALIS 2024 results show ~1 in 3 teachers across OECD already used AI, with very high reported use in some systems (e.g., Singapore, UAE) [[64]](https://www.oecd.org/en/publications/results-from-talis-2024_90df6235-en/full-report/teaching-for-today-s-world_eefb146b.html). This suggests rapid normalization of teacher-facing planning and summarization—and a more cautious ramp for student-facing tools via walled gardens [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).

### Trend 2 — **Assessment redesign becomes the central battleground**
The strongest practical school responses are not “detectors,” but redesigned assessment workflows (NZ checkpoints/version histories; Canada AI-aware rubrics) [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf), [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf). Expect widespread adoption of:
- checkpointed drafting,
- version history evidence,
- oral defenses/performance tasks,
- explicit AI-use disclosure norms.

### Trend 3 — **Provenance and “agency labeling” standards move from optional to expected**
NIST’s GenAI risk profile highlights content provenance and incident disclosure as core governance elements [[67]](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf). Technical ecosystems are maturing:
- C2PA provenance specifications for tamper-evident media histories [[66]](https://c2pa.org/specifications/specifications/2.3/specs/C2PA_Specification.html),
- watermarking standardization pressure (ITU discussion) [[68]](https://www.itu.int/hub/2024/05/ai-watermarking-a-watershed-for-multimedia-authenticity/),
- IEEE 3152 for transparent human vs machine agency identification markers [[69]](https://www.computer.org/csdl/magazine/co/2025/11/11220790/2bddegeZvY4).  
Education systems will increasingly expect “show your work” not only in math, but in **media authenticity** (especially to counter deepfakes and misinformation in school communities).

### Trend 4 — **Regulation-driven procurement and AI management systems**
Formal AI management approaches (e.g., ISO/IEC 42001 AI management system standard) will increasingly inform district procurement, risk assessment, and vendor requirements [[72]](https://www.iso.org/standard/42001). EU AI Act enforcement beginning Aug 2026 is a key global forcing function for transparency and governance features [[73]](https://ai-act-service-desk.ec.europa.eu/en/ai-act/timeline/timeline-implementation-eu-ai-act).

### Trend 5 — **Equity becomes the differentiator**
Cases highlight real risks of unequal access (Kenya teacher concern; connectivity limitations) [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/), and UNESCO/OECD frame equity and inclusion as core constraints to manage [[1]](https://unesdoc.unesco.org/ark:/48223/pf0000386693), [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html). The Nigeria pilot suggests well-designed, teacher-supported models can produce large gains even in low-resource contexts—if infrastructure and onboarding are solved [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria), [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).

---

## 8) Recommendations for educators (actionable, classroom-tested, and system-aware)

### 8.1 A phased adoption roadmap (practical for schools)
**Phase 0 — Readiness and guardrails (2–6 weeks)**
- Decide tool access model: teacher-only first vs student access; prioritize platform/walled garden if available [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education).
- Set non-negotiables: no PII in prompts; teacher remains responsible for outputs [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf), [[35]](https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education/generative-artificial-intelligence-ai-in-education).
- Establish an AI-use disclosure norm (“AI-assisted” statement) [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf).
- Build staff baseline AI literacy aligned to UNESCO’s teacher competency dimensions (ethics, pedagogy, foundations) [[61]](https://www.unesco.org/en/articles/ai-competency-framework-teachers), [[62]](https://www.cedefop.europa.eu/files/unesco_ai_competency_framework_for_teachers.pdf).

**Phase 1 — Teacher-facing productivity (low risk, high benefit)**
- Use AIGC for: lesson variants, question banks, exemplars (including flawed exemplars for critique), differentiation drafts.
- Mandatory routine: cross-check against curriculum/textbook (Kenya practice) [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/).

**Phase 2 — Student-facing structured use (bounded)**
- Use OSPI-like scaffolding levels: start with Level 2 brainstorming and Level 3 drafting with required revision logs and citations [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf).
- Avoid “open-ended free chat” early; use structured prompts and teacher monitoring.

**Phase 3 — Deep integration (units + assessment redesign)**
- Redesign assessment for authenticity:
  - checkpoints + version history + oral defense (NZ model) [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf),
  - ownership/performance evidence (Canada model) [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).

### 8.2 A teacher’s “AIGC lesson design checklist”
Before the lesson:
- What is the learning objective *that AI cannot do for them*?
- What OSPI level is allowed in each phase? [[19]](https://ospi.k12.wa.us/sites/default/files/2024-06/ai-guidance_classroom-considerations.pdf)
- What verification will be required (sources, experiments, calculations, peer review)?

During:
- Model one interaction and critique it publicly (accuracy, bias, usefulness).
- Require students to keep a minimal prompt/use log for transparency.

After:
- Collect reflections: what did AI help with, what did it get wrong, what did the student change?
- Require an “AI assistance statement” (even if “none used”).

### 8.3 Category-specific do’s and don’ts (based on cross-case risks)

**For tutoring/dialogue**
- Do: teacher-orchestrated prompts + reflection (Nigeria) [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).
- Don’t: let AI become the unquestioned authority; verify.

**For feedback tools**
- Do: treat AI feedback as “first-pass,” teacher-reviewed (Singapore) [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).
- Don’t: outsource summative judgment without policy support; OECD governance discussions flag grading/feedback as an area needing caution [[17]](https://www.oecd.org/en/publications/oecd-digital-education-outlook-2023_c74f03de-en/full-report/emerging-governance-of-generative-ai-in-education_3cbd6269.html).

**For role-play/simulation**
- Do: pair with sourcing tasks (“What evidence supports this claim?”).
- Don’t: use uncritically in history/civics; Germany case highlights bias and fabricated/unsupported narratives risk [[7]](https://www.berghahnjournals.com/view/journals/jemms/16/2/jemms160206.xml).

**For SEND/inclusion**
- Do: explicitly teach metacognitive strategies (“ask for hints, not answers”) and align supports to UDL [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).
- Don’t: assume more access equals more agency [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).

### 8.4 What schools and districts should build (so teachers can succeed)
- **A consistent policy + classroom language** (NZ cases show inconsistency breeds confusion) [[10]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Aotea%20College_MAR2025.pdf), [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf).
- **Approved tool process** and data protection review (common in EU-aligned guidance and major districts) [[33]](https://www.eursc.eu/BasicTexts/2025-01-D-66-en-2.pdf).
- **Professional development** that is not only “how to prompt,” but ethics, bias, verification, assessment redesign (UNESCO competency framing) [[61]](https://www.unesco.org/en/articles/ai-competency-framework-teachers), [[62]](https://www.cedefop.europa.eu/files/unesco_ai_competency_framework_for_teachers.pdf).
- **Equity plan**: access at school, alternatives for home, and explicit supports for students lacking connectivity (Kenya/Nigeria constraints) [[78]](https://restofworld.org/2025/ai-teaching-tools-kenya-teacher-shortage/), [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria).

---

## 9) Key gaps in the global evidence base (important for responsible conclusions)
- Empirical K–12 studies are still geographically skewed; systematic review evidence shows gaps (notably Africa underrepresented, though Nigeria is a standout recent case) [[27]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1647573/full), [[75]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-Transforming-learning-in-Nigeria).  
- Many studies emphasize perceptions/engagement more than objective learning outcomes [[27]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1647573/full).  
- Lesson workflows are often under-specified, limiting replication [[27]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1647573/full).  
- Some widely cited implementations are based on press releases or news reports (useful signals, but not causal evidence) [[85]](https://www.utahbusiness.com/press-releases/2024/02/08/schoolai-jordan-school-district-ai-partnership/), [[8]](https://www.straitstimes.com/singapore/askst-what-are-moe-s-newest-artificial-intelligence-tools-and-how-are-schools-using-them).

---

## Bottom line (cross-case insight)
The most robust classroom implementations are not “students ask ChatGPT anything.” They are **structured learning systems** where:
- teachers orchestrate and constrain AIGC use (Nigeria; Uruguay) [[76]](https://blogs.worldbank.org/en/education/From-chalkboards-to-chatbots-in-Nigeria), [[4]](https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1288723/full),
- platforms provide bounded tools with guardrails (Singapore SLS) [[38]](https://www.moe.gov.sg/education-in-sg/educational-technology-journey/edtech-masterplan/artificial-intelligence-in-education),
- assessment is redesigned around process evidence and oral/performance proof (New Zealand; Canada) [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf), [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf),
- and inclusion is treated as a design problem requiring UDL-aligned scaffolds (Australia disability case) [[6]](https://bera-journals.onlinelibrary.wiley.com/doi/10.1111/bjet.70048).

If you want, I can also produce:
1) a **one-page framework poster** (categories + decision rules + OSPI levels) for staff rooms,  
2) **ready-to-run lesson templates** (primary and secondary) for each category, and  
3) an **AI-aware assessment toolkit** (checkpoint schedule + version-history rubric + oral defense prompts) aligned to the New Zealand and Canada patterns [[11]](https://web-assets.education.govt.nz/s3fs-public/2025-03/GenAI%20Case%20Study%20Hobsonville%20Point%20Secondary%20School_MAR2025.pdf), [[12]](https://c21canada.org/wp-content/uploads/2025/08/ON-TDSB-1-PDF-AIUseCase-2025.pdf).
