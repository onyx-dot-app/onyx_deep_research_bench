Query ID: 92
============================================================

QUESTION:
For a research project titled 'Analysis and Study of Singles Badminton Player Actions Using Sports Videos,' please refine and optimize the following four research components: 1) Object Detection and Tracking within Badminton Videos; 2) Recognition of Technical Actions performed by Singles Players; 3) Recognition of Tactical Intent behind Singles Players' Actions; 4) Prediction of Singles Players' Subsequent Actions.

============================================================

RESEARCH TASKS (6 total):
  #1: Research and propose a state-of-the-art (circa 2024-2026) design for object detection and tracking in singles badminton videos, covering players, shuttlecock, racket, court lines/keypoints, and pose/foot keypoints. Include best practices for handling fast shuttle motion blur, occlusion, camera zoom/cuts, multi-view vs broadcast, and give recommended model families (detectors, MOT, trackers, pose estimators) plus data annotation considerations and evaluation metrics.
  #2: Research and propose an optimized approach for recognizing fine-grained technical actions in singles badminton from video, including stroke types (serve, clear/lift, drop/slice drop, smash, drive, net shot, block, push, defense), footwork patterns, and rally phase transitions. Summarize best model families (video transformers, multi-stream RGB+pose+trajectory, graph models), temporal segmentation/boundary methods, multi-label handling, and label taxonomy recommendations with unambiguous definitions and evaluation protocols.
  #3: Research how to operationalize and recognize tactical intent in singles badminton from sports videos and derived signals (player positions, shuttle trajectory/landing zones, shot selection). Propose meaningful intent categories and hierarchical labels, and summarize modeling approaches (relational/causal models, intent from state-action sequences, inverse RL, game-theoretic/agent interaction, graph neural nets) and methods to avoid label leakage. Include annotation strategies and evaluation metrics.
  #4: Research state-of-the-art (2024-2026) methods and target definitions for predicting singles badminton players' subsequent actions from video/derived stroke sequences: next stroke type, landing zone, player movement, rally outcome. Include relevant datasets (e.g., ShuttleSet, ShuttleNet, newer datasets), modeling strategies (transformers over rallies, diffusion/latent-variable models, multi-agent interaction), uncertainty handling, and evaluation metrics/protocols that avoid leakage.
  #5: Research evaluation protocols and metrics for an end-to-end singles badminton video understanding system spanning detection/tracking, technical action recognition, tactical intent recognition, and next-action prediction. Include component-wise metrics (MOT, keypoints, segmentation, classification), pipeline-level metrics, cross-tournament/domain generalization, latency/efficiency constraints, and error propagation/ablation best practices (2024-2026).
  #6: Research and propose an unambiguous hierarchical taxonomy for singles badminton video understanding that links: entities (players/shuttle/court), events (hit/serve/rally start/end), technical strokes and footwork, phases of rally, tactical semantics/intent, and prediction targets. Use evidence from existing datasets (e.g., ShuttleSet 18 shots, FineBadminton multi-level semantics) and propose definitions/temporal grounding suitable for broadcast and training-court videos.

============================================================

ANSWER:
### Shared foundations (so the 4 components align end-to-end)

#### A. Minimal but complete **hierarchical taxonomy** (labels that stay unambiguous across broadcast + training-court video)
Use a *two-layer* approach: (i) **observable, objectively labelable** primitives (entities/events/geometry), then (ii) **semantic labels** (technical actions, tactics, predictions) that are always tied back to those primitives.

1) **Entities (per-frame / per-track)**
- **Player-A / Player-B** (identity within a rally; optionally global identity across match).
- **Shuttlecock** (2D image position + confidence; optionally 3D).
- **Racket** (optional; often hard in broadcast—treat as “nice-to-have” unless you can annotate reliably).
- **Court geometry**: court corners / keypoints, lines, net line; plus a homography to map image → court coordinates (critical for tactics/prediction) as done in ShuttleSet-style processing [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).

2) **Core events (timestamped, “action spotting” style)**
- **RallyStart / RallyEnd** (rally segmentation).
- **HitEvent** (racket–shuttle contact moment; one timestamp per stroke).
- Optional: **Bounce/Land** (shuttle landing) and **Fault/Out/Net** (end reason).

3) **Stroke record (per HitEvent) — the “single source of truth”**
Model your per-stroke record after what has proven useful in large-scale singles datasets:
- **ShotType**: start with an established taxonomy (e.g., ShuttleSet 18 types) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).
- **Landing (destination)**: continuous (x,y) on court + discretized zone/grid.
- **Hitting location**: (x,y) of hitter at contact + discretized zone.
- **Opponent location** at contact.
- **Attributes** that reduce ambiguity and improve modeling: backhand, around-the-head, above/below-net height indicator (used in ShuttleSet-style labeling) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/) and in newer benchmark formats [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- **Outcome fields** (only at rally end): point winner + reason for loss (ShuttleSet-style) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/), and equivalent outcome fields exist in ShuttleSet22 columns [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

4) **Tactical semantics (per stroke OR short stroke-window)**
Adopt a *separate* layer that can be predicted from the stroke record + trajectories:
- FineBadminton shows a workable hierarchy: **Foundational Actions → Tactical Semantics (intent) → Decision Evaluation** [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).
- Tactical semantics examples explicitly include **deception**, **defensive play**, **passive/transitional shot**, plus trajectory/placement semantics like straight vs cross-court and opponent-relative ideas like body shot/passing shot [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).  
This layer is where “intent” lives, but it must be grounded in observable state/action.

5) **Prediction targets**
Stay consistent with how the community already benchmarks “next action”:
- **Next ShotType + Next Landing (x,y)** is the core in ShuttleNet/ShuttleSet22-style forecasting tasks [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- **Next player movement / next positions** is a second target family (movement forecasting exists as a formal task) [[22]](https://arxiv.org/html/2403.12385v1).
- **Rally outcome / shot influence** is a third family (win/lose probability per stroke) [[23]](https://arxiv.org/html/2502.21085v1).

---

## 1) Object Detection and Tracking within Badminton Videos (optimize for shuttle speed + camera motion)

### 1.1 Refined problem statement (what to detect/track, and why)
Your downstream tasks (action, intent, prediction) require **court-registered trajectories** and **hit-centric temporal anchors**. Therefore, treat detection/tracking as 4 coupled subproblems:

1) **Court registration** (per segment / per camera view)
- Detect court lines/keypoints → estimate homography image→court coordinates.
- Needed to express landing zones, player positions, and tactics in a consistent coordinate system (central to ShuttleSet-style structured records) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).

2) **Shuttlecock tracking** (high-speed tiny object)
- Shuttle is small + motion blur + occlusion; use specialized trackers (TrackNet-family is explicitly designed for “high-speed and tiny objects” in sports) [[7]](https://arxiv.org/abs/2304.08069).
- Badminton pipelines often fuse shuttle tracking with swing/action cues and refinement because TrackNet alone produces misses/false detections in broadcast [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

3) **Player detection + multi-object tracking (MOT)**
- Stable player tracks are necessary for relative positioning, movement features, and player-conditioned forecasting.

4) **Pose/feet keypoints** (top-down per player track)
- Needed for technique/footwork features and for models like pose-conditioned stroke forecasting (see RallyTemPose-style design) [[20]](https://openreview.net/pdf).

---

### 1.2 Recommended 2026-style architecture (robust to cuts/zooms)
**A. Segment the video into “camera-consistent” chunks**
- Detect **hard cuts** and large viewpoint changes (broadcast). Reset court registration and trackers at each segment boundary.
- Motivation: sports broadcasts frequently switch cameras; tracking purely in image space is vulnerable to camera motion and transitions [[9]](https://arxiv.org/abs/2206.14651).

**B. Court-first (register-then-track)**
- Use a **register-then-track** strategy: estimate court anchors/keypoints, then map detections to court coordinates to stabilize tracking across camera motion. This directly matches the motivation of FieldMOT (sports broadcast MOT robustness through field registration) [[9]](https://arxiv.org/abs/2206.14651).

**C. Dual-space tracking**
- Track in **image space** (for association) *and* maintain a **court-space trajectory** (for smoothing and tactical features).
- When the camera pans/zooms, court-space continuity helps you detect ID switches and re-associate after short occlusions.

---

### 1.3 Model choices (pragmatic, strong, and up to date)

#### (1) Court lines / keypoints
Options:
- **Classical + learning hybrid**: badminton court line extraction methods explicitly address occlusion/clutter; one approach uses 1D histogram projection and learned intensity patterns to locate line positions more efficiently than Hough-based approaches [[8]](https://arxiv.org/abs/2110.06864).
- **Keypoint detection**: lightweight court keypoint datasets/models exist publicly (small-scale, e.g., ~200 images on Roboflow) [[13]](https://universe.roboflow.com/learning-9i34b/badminton-court-keypoint-dataset)—useful for bootstrapping, but expect to extend with your own annotations.

**Deliverable**: per segment, output homography + court coordinate frame consistent with badminton dimensions (13.4m × 6.1m is used in ShuttleSet-style mapping) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).

#### (2) Player detection
- Use a modern real-time detector family; two strong directions:
  - **YOLOv10** (focuses on NMS-free training and latency/efficiency) [[10]](https://arxiv.org/abs/2203.14360).
  - **RT-DETR** (real-time end-to-end DETR variant, avoids NMS and supports speed tuning by decoder layers) [[11]](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Observation-Centric_SORT_Rethinking_SORT_for_Robust_Multi-Object_Tracking_CVPR_2023_paper.pdf).

**Best practice**: fine-tune on badminton frames (broadcast + training-court) with labels for full body boxes; include difficult poses (lunges, dives) and partial occlusions.

#### (3) Player multi-object tracking (MOT)
Use tracking-by-detection with strong occlusion handling:
- **ByteTrack**: associates *low-score detections* too, improving robustness under occlusion and reducing fragmented tracks [[12]](https://medium.com/@jumabek4044/day-33-multi-object-tracking-study-4abb28ddecdd).
- **BoT-SORT**: combines motion + appearance and includes **camera-motion compensation**, useful for broadcast panning/zooming [[13]](https://universe.roboflow.com/learning-9i34b/badminton-court-keypoint-dataset).
- **OC-SORT**: explicitly targets occlusion/non-linear motion by “re-updating” tracks using observation-centric virtual trajectories after occlusion [[14]](https://github.com/CMU-Perceptual-Computing-Lab/openpose).

**Recommendation**: start with BoT-SORT (camera-motion compensation) [[13]](https://universe.roboflow.com/learning-9i34b/badminton-court-keypoint-dataset) and test ByteTrack [[12]](https://medium.com/@jumabek4044/day-33-multi-object-tracking-study-4abb28ddecdd) as a simpler strong baseline; include OC-SORT [[14]](https://github.com/CMU-Perceptual-Computing-Lab/openpose) when occlusion-driven fragmentation dominates.

#### (4) Shuttlecock tracking
- Use TrackNet-family models; TrackNet is explicitly designed for tiny fast sports objects [[7]](https://arxiv.org/abs/2304.08069).
- In badminton broadcast, a practical pipeline is: **TrackNet for shuttle trajectory + YOLO for swing detection + post refinement** to correct misses/false detections and infer hit moments [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370). This significantly improved shot extraction F1 in a large evaluation compared with TrackNet alone [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

**Key optimization**: treat shuttle tracking as *trajectory estimation*, not independent frame detections:
- Add trajectory smoothing, physically plausible motion constraints, and gap filling (the need for a refinement stage is shown empirically in badminton broadcast) [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

#### (5) Pose / feet keypoints
- **RTMW** (whole-body pose, includes feet, emphasizes resolution for small parts like feet) [[15]](https://arxiv.org/html/2407.08634v1).
- Implement via **MMPose** (toolbox supports whole-body keypoints and many SOTA models) [[16]](https://github.com/open-mmlab/mmpose).
- OpenPose also explicitly supports foot keypoints (practical baseline, but often less accurate than newer models) [[17]](https://arxiv.org/abs/2204.12484).
- ViTPose is a strong transformer baseline for pose estimation [[18]](https://arxiv.org/html/2412.13490v1).

**Pragmatic setup**:
- Track players → crop person boxes → run top-down whole-body pose (RTMW via MMPose) [[15]](https://arxiv.org/html/2407.08634v1)[[16]](https://github.com/open-mmlab/mmpose).
- Ensure feet keypoints are stable; footwork features degrade sharply if ankle/toe points jitter.

---

### 1.4 Hit-event extraction as a first-class output (because everything depends on it)
You need reliable **HitEvent timestamps** to:
- segment strokes for technical classification (BST-style pipelines do explicit swing-centric segmentation) [[19]](https://joiv.org/index.php/joiv/article/view/2132),
- generate per-stroke records (ShuttleSet format) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/),
- feed forecasting models (stroke sequences) [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

A proven pattern in badminton broadcast is to fuse:
- shuttle trajectory (TrackNet),
- swing/action detection (YOLO),
- and a refinement algorithm to determine correct hit moments [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

**Evaluation**: treat HitEvent as event spotting; use mAP with temporal tolerance windows (mAP@δ), as standardized in sports action spotting protocols (SoccerNet describes unique matching under tolerance windows) [[25]](https://arxiv.org/abs/1903.01945). For badminton, define δ in frames (e.g., ±3, ±5, ±10 frames) and report the curve.

---

### 1.5 What to annotate (so training data is efficient, not bloated)
Minimum annotation set for an effective pipeline:
- Court keypoints/corners (for homography) on representative frames per segment.
- Player boxes for detection fine-tuning.
- HitEvent timestamps for a subset (to supervise/refine hit spotting).
- Shuttle positions for short windows around hits (to supervise TrackNet adaptation).
- Pose is usually trained from generic datasets; you only annotate pose if badminton-specific poses (extreme lunges/dives) break generalization.

If you build a ShuttleSet-like structured dataset, consider a “shot-by-shot” annotation tool workflow (ShuttleSet used an expert labeling tool with per-stroke time/locations/attributes/shot type) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).

---

### 1.6 Metrics (component-level)
- **MOT**: report **HOTA**, which explicitly balances detection, association, and localization and decomposes error types [[24]](https://arxiv.org/abs/2204.01899).
- **Pose**: use OKS/mAP style evaluation (COCO pose protocol uses OKS and mAP) [[49]](https://docs.ultralytics.com/datasets/pose/coco/).
- **HitEvent spotting**: mAP@δ (sports spotting protocol) [[25]](https://arxiv.org/abs/1903.01945).
- **Shuttle trajectory**: trajectory continuity metrics + hit-window localization accuracy (even if you also report shot extraction F1 like the TrackNet+YOLO+refinement pipeline did) [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

---

## 2) Recognition of Technical Actions performed by Singles Players (strokes + footwork + transitions)

### 2.1 Refined scope: separate “what happened” into 3 aligned outputs
1) **Stroke classification** (per HitEvent)
- Output: ShotType (start with ShuttleSet 18) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/), optionally extend to finer subtypes (FineBadminton has 11 primary + 20 subtypes at foundational level) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).

2) **Technical attributes** (multi-label per HitEvent)
- backhand / around-the-head / above-vs-below-net-height style flags are already shown useful in structured datasets and benchmarks [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

3) **Footwork & movement pattern recognition**
- Two levels:
  - **Instantaneous**: stance, lunge, jump, split-step indicators (derived from pose/feet).
  - **Short temporal pattern**: approach-to-net, retreat-to-rear-court, lateral recovery, etc. (derived from court-space trajectories + feet).

Because no provided source defines a universal discrete footwork label set, keep footwork as (a) derived continuous descriptors and (b) optional clustered/learned discrete patterns unless you can label reliably.

---

### 2.2 Temporal representation: hit-centric beats frame-centric for badminton
Badminton strokes are brief and visually similar (many look like generic “hitting”). Recent badminton-specific modeling argues shuttle trajectory is crucial for disambiguation; BST explicitly treats shuttle trajectory as central because motion alone can be ambiguous [[19]](https://joiv.org/index.php/joiv/article/view/2132).

**Best practice**: represent each stroke with a **hit-centered window**:
- pre-hit (preparation),
- hit moment,
- short post-hit (follow-through + shuttle departure).

This aligns with pipelines that explicitly segment swing-centric frames before classification (BST-style) [[19]](https://joiv.org/index.php/joiv/article/view/2132) and with video pipelines that refine hit moments for accurate stroke extraction [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).

---

### 2.3 Input modalities: use multi-stream (RGB + pose + shuttle trajectory + court-space positions)
A strong, research-aligned fusion set is:
- **Pose stream**: skeletal joints (whole-body, include feet) [[15]](https://arxiv.org/html/2407.08634v1)[[16]](https://github.com/open-mmlab/mmpose).
- **Shuttle trajectory stream**: 2D (and optionally 3D) trajectory around the hit; trajectory is repeatedly highlighted as critical in badminton [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370)[[19]](https://joiv.org/index.php/joiv/article/view/2132).
- **Court-space positions**: hitter/opponent positions at contact and recent motion; these are explicitly part of structured stroke records in ShuttleSet/ShuttleSet22 [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- **RGB / cropped player clip**: helps capture racket cues and subtle wrist actions when pose is insufficient.

**Why this is consistent with the literature you already have**
- BST uses skeleton joints + shuttle trajectory + player positions for stroke-type recognition and reports outperforming prior approaches on ShuttleSet [[19]](https://joiv.org/index.php/joiv/article/view/2132).
- FineBadminton’s structural parsing stage explicitly combines ball/player coordinates with video features (VideoMAE features around hits) and uses task heads for stroke type + landing spot [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).

---

### 2.4 Model families to prioritize (2026-appropriate)
#### A. Stroke-type classification (per hit window)
1) **Transformer fusion models (recommended primary)**
- Follow the BST principle: treat shuttle trajectory as a primary signal and model interaction via shuttle as the medium in singles [[19]](https://joiv.org/index.php/joiv/article/view/2132).
- Use a cross-attention fusion block: pose ↔ shuttle trajectory ↔ positions; optionally add RGB tokens.

2) **Skeleton-based action recognition backbones**
BST’s review notes rapid progress in both GCN-based and transformer-based skeleton action recognition; it positions transformer-based approaches as competitive and suitable for subtle actions [[19]](https://joiv.org/index.php/joiv/article/view/2132).  
In practice, you can:
- encode pose with a spatial transformer + temporal transformer (similar in spirit to RallyTemPose’s spatiotemporal pose encoder design for forecasting) [[20]](https://openreview.net/pdf),
- fuse with shuttle trajectory embeddings.

#### B. Temporal segmentation in untrimmed rallies (optional but valuable)
If you want frame-level labels across long rallies (not just per-hit classification), use temporal action segmentation (TAS) models:
- **MS-TCN**: multi-stage temporal refinement with smoothing loss to reduce over-segmentation [[27]](https://yiskw713.github.io/asrf/).
- **ASFormer**: transformer-based segmentation with local inductive priors + hierarchical long-sequence handling [[28]](https://arxiv.org/html/2405.15995v1).
- **ASRF**: explicitly predicts boundaries to refine segments and reduce over-segmentation [[29]](https://arxiv.org/pdf/2306.04948).
- **BaFormer**: boundary-aware query-based segmentation designed for efficiency in long videos [[30]](https://cdn.aaai.org/ojs/20341/20341-13-24354-1-2-20220628.pdf).

**Badminton-specific adaptation**: use HitEvent timestamps as strong boundary priors (hard/soft constraints) so TAS does not drift.

---

### 2.5 Handling fine-grained ambiguities (clear vs lift, drop vs slice drop, etc.)
You can make these distinctions unambiguous by defining them with **trajectory + contact context**, not just appearance:
- Define label rules using:
  - shuttle departure angle and speed (from TrackNet trajectory),
  - landing depth/side (court coordinates),
  - hitter position (rear-court vs fore-court),
  - and above/below-net indicator where available (used as a meaningful attribute in structured labeling) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

This mirrors the philosophy visible in FineBadminton: “foundational actions” are enriched by trajectory/placement semantics and then lifted into tactical meaning [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).

---

### 2.6 Evaluation (technical actions)
- **Per-stroke classification**: accuracy, macro-F1 (imbalance is explicitly an issue in ShuttleSet shot types) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).
- **Hit detection / stroke extraction**: report precision/recall/F1 like the TrackNet+YOLO+refinement approach did at scale [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370).
- **Temporal segmentation**: segmental F1/edit distance (standard in TAS methods like ASRF/BaFormer) [[29]](https://arxiv.org/pdf/2306.04948)[[30]](https://cdn.aaai.org/ojs/20341/20341-13-24354-1-2-20220628.pdf).
- **Cross-domain tests**: train on broadcast, test on training-court (and vice versa) to quantify domain shift.

---

## 3) Recognition of Tactical Intent behind Singles Players’ Actions (operationalize intent without “mind reading”)

### 3.1 Refined definition: “intent” = latent objective conditioned on state, revealed by action + immediate consequences
To avoid subjective labels floating free of evidence:
- Define intent as a function of:
  - **state at hit**: hitter/opponent positions, rally context (score optional), recent strokes,
  - **action**: shot type + placement,
  - **immediate consequence**: shuttle trajectory/landing and opponent displacement in the next 1–2 strokes.

FineBadminton explicitly structures this as a hierarchy where Tactical Semantics “infer player intent,” including deception and defensive/passive/transitional intent, grounded in ball movement dynamics and context [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).

---

### 3.2 Intent taxonomy: a practical hierarchy that matches available evidence
Use FineBadminton’s idea but make it implementable as *predictable labels*:

**Level 1: Tactical mode (3-way, explicitly aligned with FineBadminton examples)**
- **Offensive/attacking**
- **Defensive**
- **Neutral / passive / transitional** (FineBadminton explicitly uses passive/transitional as intent-like semantics) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html)

**Level 2: Strategic objective (examples consistent with FineBadminton tactical semantics)**
Ground these in *trajectory + opponent-relative semantics*:
- **Create space** (move opponent, open court)
- **Pressure body / jam** (body-shot style semantics exist as examples) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html)
- **Pass opponent / wrong-foot** (passing-shot semantics exist as examples) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html)
- **Exploit corner / depth** (placement-driven)
- **Force weak return** (proxy by opponent displacement + next-shot difficulty)

**Level 3: Deception (binary or small set)**
- **Deceptive vs non-deceptive** (deception is explicitly named as intent in FineBadminton) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html)

**Level 4: Shot characteristics / trajectory semantics (descriptive)**
- straight vs cross-court, etc. (trajectory semantics are explicit examples) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html)

You can keep this hierarchy “clean” by ensuring each label has a measurable rule or annotation guideline tied to positions/trajectory.

---

### 3.3 Modeling approaches that fit singles badminton (two-player interaction, shuttle-mediated)
#### A. Supervised intent classification with structured inputs (baseline, strong and interpretable)
Input features (per stroke or short stroke window):
- shot type, landing coordinates/zone, hitter/opponent positions, above/below net, backhand/around-head [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838),
- shuttle trajectory descriptors (shape, speed proxies),
- opponent displacement and response type over next stroke(s) (if allowed by task definition).

Model families:
- Transformer over stroke sequences (consistent with ShuttleNet-style rally modeling) [[21]](https://arxiv.org/abs/2306.04948).
- Add interaction blocks (because intent is relational).

#### B. Relational / graph modeling (especially for “pressure” and “opponent exploitation”)
Even though TacticAI is football, it demonstrates why graph relational inductive bias matters: tactics are about relationships, not absolute coordinates; it uses message passing and symmetry constraints for robustness [[32]](https://arxiv.org/html/2508.07554v1).  
For badminton singles, the “graph” is tiny (two players + shuttle), but the same idea applies:
- a relational module over {hitter, opponent, shuttle-state} can model pressure and response.

#### C. Weakly supervised tactical semantics via FineBadminton-style hierarchical labels
FineBadminton provides a blueprint: structural parsing → semantic interpretation → evaluation refinement [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).  
Even if you don’t replicate the full MLLM pipeline, you can:
- train intent classifiers on the tactical semantics labels,
- and use textual descriptions as auxiliary supervision (multi-task) to regularize intent representations.

---

### 3.4 Minimizing label leakage (critical for intent and prediction)
Intent labels can easily leak future information if not defined carefully.

**Rules**
1) If the task is **online intent recognition at contact time**:
- Only allow features available up to (or minimally after) HitEvent (e.g., ≤200ms post-hit).
- Do *not* include “rally winner” or loss reason, which are explicitly recorded and only known at rally end [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

2) If the task is **offline intent recognition (post-hoc analysis)**:
- You may use the immediate consequence (landing spot, opponent’s forced movement), but still avoid using far-future outcomes that trivially reveal “good/bad” intent.

3) **Data split discipline**
- Use chronological or match-based splits to prevent training on future contexts. Leakage is a known failure mode when preprocessing/splitting mixes information improperly [[33]](https://www.nature.com/articles/s41467-024-45965-x), and time-respecting splits are a common safeguard in predictive tasks [[34]](https://arxiv.org/pdf/2310.10553).
- ShuttleSet explicitly allows custom splits, so you must document them rigorously [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/).

---

### 3.5 Evaluation (intent)
Because badminton-specific “intent” metrics aren’t standardized in the provided sources, adopt a transparent multi-metric scheme:
- **Hierarchical accuracy** (Level-1 mode, Level-2 objective, deception).
- **Macro-F1** for imbalance.
- **Calibration** (intent probabilities should be meaningful for coaching usage).
- **Counterfactual sanity checks**: swap court halves (symmetry) and verify intent predictions stay consistent (inspired by symmetry-aware sports modeling ideas) [[32]](https://arxiv.org/html/2508.07554v1).

---

## 4) Prediction of Singles Players’ Subsequent Actions (define targets + models + uncertainty properly)

### 4.1 Target definition: match what is already benchmarked, then extend
A strong staged target set is:

**Core (must-have; directly benchmarked)**
- **Next ShotType + Next Landing (x,y)**  
This is exactly the ShuttleNet/ShuttleSet22 forecasting setup: predict “what” and “where” the next strokes go [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838)[[21]](https://arxiv.org/abs/2306.04948).

**Extended (high value)**
- **Next player movement / next positions**  
Movement forecasting is established as a task (predict where players move next in addition to strokes) [[22]](https://arxiv.org/html/2403.12385v1).

**Outcome-level**
- **Rally win probability / shot influence**  
Shot influence work frames this as rally win/lose prediction from shot-by-shot sequences, then uses attention for interpretability [[23]](https://arxiv.org/html/2502.21085v1).

**Multi-step**
- Predict next *k* strokes (turn-based rollouts). ShuttleSet22 forecasting explicitly predicts multiple future strokes with horizon tied to rally length [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

---

### 4.2 Modeling strategies (what works in singles badminton, given your available signals)

#### A. Turn-based rally transformers (state-of-practice baseline)
- **ShuttleNet**: transformer encoder-decoder designed for turn-based structure, fusing rally progress + player styles, predicting what/where to return [[21]](https://arxiv.org/abs/2306.04948).
- **ShuttleSet22 benchmark** is built around this paradigm and shows many teams improved type prediction while location remained harder, highlighting the importance of better joint modeling for discrete+continuous outputs [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

**Optimization idea** (based on benchmark observation):
- decouple heads (type vs landing) with shared trunk + cross-head consistency constraints, because simply improving one often doesn’t improve the other [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

#### B. Add motion/pose for partial observability (strong research direction)
- **RallyTemPose** explicitly predicts the next stroke using previous strokes plus **2D skeleton pose sequences** and ground motion, and uses a transformer encoder-decoder with inter-/intra-player attention [[20]](https://openreview.net/pdf).  
This is directly aligned with your project title (sports videos) because it bridges from video-derived pose to forecasting.

#### C. Joint forecasting of stroke + movement (interaction-aware)
- **DyMF** proposes dynamic graphs and hierarchical fusion for movement forecasting, motivated by interaction effects and evolving tactics [[22]](https://arxiv.org/html/2403.12385v1).

A practical combined model:
- trunk: rally transformer (turn-based),
- auxiliary encoders: pose/motion encoder (RallyTemPose-like) [[20]](https://openreview.net/pdf) + interaction/movement module (DyMF-like) [[22]](https://arxiv.org/html/2403.12385v1),
- outputs: next stroke distribution + landing distribution + next positions.

---

### 4.3 Uncertainty and multi-modality (don’t force a single future)
Badminton forecasting is inherently multi-modal; ShuttleSet22 formalizes this by requiring **multiple predicted sequences per rally** and scoring the **closest** sample to ground truth (“best-of-K”), using 6 generated sequences for efficiency [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).  
This has two direct implications for your research design:

1) Your model should be able to **sample diverse plausible futures** (not only output a mean).
2) Report both:
- **best-of-K** performance (to align with the benchmark protocol) [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838),
- and **expected** performance (e.g., likelihood or average error) so you don’t hide mode collapse.

---

### 4.4 Evaluation protocol (forecasting)
Use what the benchmark already standardizes, then add realism checks.

**Benchmark-aligned metrics (stroke forecasting)**
- **Cross-entropy** for shot type prediction and **MAE** for landing coordinate regression are explicitly used in ShuttleSet22 evaluation [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- Keep them separate *and* report the combined score if you need a single number, because the benchmark explicitly shows improvements often concentrate on CE while MAE may stagnate/worsen [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).

**Additional recommended slices**
- By shot type (services only at first stroke; distributions differ) [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- By backhand/around-head/landing-height flags (these columns exist and show strong biases per shot type) [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- By rally phase (early vs late strokes), because decision space changes as rallies develop.

**Leakage control**
- Do not use rally-end labels (“get point player”, “reason for loss”) as features when predicting intermediate next strokes; those are explicit columns and trivially leak outcome information [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- Use match-disjoint or chronological splits (time-respecting splits are a standard anti-leakage safeguard) [[34]](https://arxiv.org/pdf/2310.10553), and follow general leakage prevention rules (preprocessing on train only) [[33]](https://www.nature.com/articles/s41467-024-45965-x).

---

## How the four components connect (recommended end-to-end optimization loop)

1) **Detection/tracking → structured stroke record**
- Court registration + player tracks + shuttle trajectory + HitEvents produce ShuttleSet-like stroke records (time, type, landing, positions, attributes) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- This record becomes the common input for technical recognition, intent, and forecasting.

2) **Technical recognition improves the stroke record**
- Better shot type / attributes reduce noise in intent recognition and next-action prediction (BST-style reasoning that trajectory + pose improves stroke type) [[19]](https://joiv.org/index.php/joiv/article/view/2132).

3) **Intent recognition regularizes prediction**
- Intent labels (FineBadminton Tactical Semantics) can be auxiliary tasks that improve forecasting representations by forcing the model to encode “why” not just “what” [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).

4) **Forecasting provides consistency checks**
- If predicted next landing/shot contradicts recognized intent (e.g., “defensive reset” but predicted “high-risk finishing smash”), flag as model inconsistency and analyze upstream errors.

---

## Concrete “refined & optimized” deliverables for your research project

### Component 1 deliverables (Object detection & tracking)
- Court homography per segment + court-space trajectories [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[9]](https://arxiv.org/abs/2206.14651).
- Player MOT tracks evaluated with HOTA [[24]](https://arxiv.org/abs/2204.01899).
- Shuttle trajectory with refinement (TrackNet-family + swing cue + postprocessing) and hit timestamps with event spotting mAP@δ [[5]](https://dl.acm.org/doi/abs/10.1145/3595916.3626370)[[25]](https://arxiv.org/abs/1903.01945).
- Pose/feet keypoints via RTMW/MMPose [[15]](https://arxiv.org/html/2407.08634v1)[[16]](https://github.com/open-mmlab/mmpose).

### Component 2 deliverables (Technical action recognition)
- Per-hit ShotType classifier (baseline: ShuttleSet 18 types) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/); optional finer foundational labels (FineBadminton hierarchy) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).
- Attribute classifiers (backhand/around-head/landing height) [[1]](https://pmc.ncbi.nlm.nih.gov/articles/PMC11244353/)[[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- Footwork descriptors (continuous + optional learned clusters) derived from feet pose + court-space movement.

### Component 3 deliverables (Tactical intent recognition)
- Hierarchical intent classifier aligned with FineBadminton tactical semantics (mode/objective/deception + trajectory semantics) [[3]](https://openaccess.thecvf.com/content/CVPR2025W/CVSPORTS/html/Chen_FieldMOT_A_Field-Registered_Multi-Object_Tracking_for_Sports_Videos_CVPRW_2025_paper.html).
- Leakage-safe experimental settings (online vs offline intent) with clearly stated feature availability rules [[33]](https://www.nature.com/articles/s41467-024-45965-x).

### Component 4 deliverables (Next-action prediction)
- Next stroke forecasting matching ShuttleSet22: CE (type) + MAE (landing), best-of-K sampling evaluation [[2]](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12838).
- Extended prediction: next movement (DyMF-style) [[22]](https://arxiv.org/html/2403.12385v1) and rally win probability/shot influence (outcome modeling) [[23]](https://arxiv.org/html/2502.21085v1).
- Pose-conditioned forecasting experiments (RallyTemPose-style) to quantify benefit of video-derived motion [[20]](https://openreview.net/pdf).

---

If you share (a) your intended video sources (broadcast-only vs mixed), (b) whether you must run near-real-time, and (c) which label sets you can realistically annotate with experts, I can translate the above into a precise experimental matrix (datasets, splits, ablations, and success criteria) consistent with the benchmarks and leakage constraints referenced here.
